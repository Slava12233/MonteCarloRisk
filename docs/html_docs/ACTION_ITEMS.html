
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Action Items: Google ADK Agent Starter Kit - MonteCarloRisk_AI</title>
        <link rel="stylesheet" href="style.css">
        <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
        <script>
            document.addEventListener('DOMContentLoaded', function() {
                mermaid.initialize({
                    startOnLoad: true,
                    theme: 'default',
                    securityLevel: 'loose',
                    flowchart: { useMaxWidth: false }
                });
            });
        </script>
    </head>
    <body>
        <div class="navbar">
            <h1>MonteCarloRisk_AI</h1>
            <p><a href="index.html" style="color: white;">‚Üê Back to Documentation Index</a></p>
        </div>
        
        <h1 id="action-items-google-adk-agent-starter-kit">Action Items: Google ADK Agent Starter Kit</h1>
<p><strong>Date:</strong> April 21, 2025<br />
<strong>Author:</strong> [Your Name], CTO<br />
<strong>Based on:</strong> Code Review Report (April 21, 2025)</p>
<h2 id="overview">Overview</h2>
<p>This document outlines the action items derived from the code review of our Google ADK Agent Starter Kit. These tasks are prioritized based on severity, impact on functionality, and alignment with our development roadmap.</p>
<h2 id="task-tracking">Task Tracking</h2>
<table>
<thead>
<tr>
<th>ID</th>
<th>Priority</th>
<th>Task</th>
<th>Owner</th>
<th>Status</th>
<th>Due Date</th>
<th>Dependencies</th>
</tr>
</thead>
<tbody>
<tr>
<td>AI-001</td>
<td>Critical</td>
<td>Fix Vertex AI Deployment Mechanism</td>
<td>CTO</td>
<td>Completed</td>
<td>May 1, 2025</td>
<td>None</td>
</tr>
<tr>
<td>AI-002</td>
<td>Medium</td>
<td>Improve CLI Extensibility</td>
<td>CTO</td>
<td>Completed</td>
<td>May 8, 2025</td>
<td>None</td>
</tr>
<tr>
<td>AI-003</td>
<td>Medium</td>
<td>Refactor Local Deployment UI</td>
<td>CTO</td>
<td>Completed</td>
<td>May 8, 2025</td>
<td>None</td>
</tr>
<tr>
<td>AI-004</td>
<td>Low</td>
<td>Align Testing Framework with Standards</td>
<td>CTO</td>
<td>Completed</td>
<td>May 15, 2025</td>
<td>None</td>
</tr>
<tr>
<td>AI-005</td>
<td>Low</td>
<td>Review Pydantic Usage</td>
<td>CTO</td>
<td>Completed</td>
<td>May 15, 2025</td>
<td>None</td>
</tr>
<tr>
<td>AI-006</td>
<td>High</td>
<td>Implement Vertex AI Agent Engine Deployment</td>
<td>CTO</td>
<td>Completed</td>
<td>May 5, 2025</td>
<td>AI-001</td>
</tr>
</tbody>
</table>
<h2 id="detailed-task-descriptions">Detailed Task Descriptions</h2>
<h3 id="ai-001-fix-vertex-ai-deployment-mechanism">AI-001: Fix Vertex AI Deployment Mechanism</h3>
<p><strong>Priority:</strong> Critical<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 1, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
The current Vertex AI deployment implementation incorrectly instantiates a generic <code>Agent</code> instead of our custom <code>SearchAgent</code> and fails to properly package tools. This renders the deployment functionality non-operational.</p>
<p><strong>Steps:</strong>
1. Completely redesign the <code>prepare_deployment_package</code> function in <code>src/deployment/vertex.py</code>
2. Ensure our custom agent classes are included in the deployment package
3. Generate a <code>main.py</code> that correctly imports and instantiates our <code>SearchAgent</code> class
4. Implement proper packaging and instantiation of tools within the Vertex AI environment
5. Ensure proper serialization of tool objects rather than just their class names
6. Add comprehensive error handling and logging</p>
<p><strong>Success Criteria:</strong>
- Successful deployment of our custom agent to Vertex AI
- Verification that the deployed agent uses our custom <code>SearchAgent</code> class
- Confirmation that all tools are properly packaged and functional
- End-to-end testing with sample queries</p>
<p><strong>Resources:</strong>
- <a href="https://cloud.google.com/vertex-ai/docs/predictions/custom-container-requirements">Vertex AI Custom Container Documentation</a>
- <a href="https://cloud.google.com/vertex-ai/docs/agent-development-kit/deployment">Google ADK Deployment Guide</a></p>
<hr />
<h3 id="ai-002-improve-cli-extensibility">AI-002: Improve CLI Extensibility</h3>
<p><strong>Priority:</strong> Medium<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 8, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
The CLI is hardcoded to support only the "search" agent type, limiting our ability to add new agent types without modifying the CLI code directly.</p>
<p><strong>Steps:</strong>
1. Design an agent registry pattern that maps agent types to their implementation classes
2. Implement the registry in a new module (e.g., <code>src/registry.py</code>)
3. Update <code>src/cli.py</code> to use this registry for creating and running agents
4. Add a mechanism for dynamically registering new agent types
5. Update documentation to reflect the new extensibility pattern
6. Add unit tests for the registry functionality</p>
<p><strong>Success Criteria:</strong>
- Ability to add new agent types without modifying the CLI code
- Successful registration and execution of at least one new agent type
- Comprehensive test coverage for the registry functionality
- Updated documentation with examples of adding new agent types</p>
<p><strong>Resources:</strong>
- <a href="https://python-patterns.guide/registry/">Python Registry Pattern Examples</a>
- <a href="https://click.palletsprojects.com/">Click Documentation</a> (if we decide to migrate to Click)</p>
<hr />
<h3 id="ai-003-refactor-local-deployment-ui">AI-003: Refactor Local Deployment UI</h3>
<p><strong>Priority:</strong> Medium<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 8, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
The current local deployment implementation generates HTML on the fly, coupling Python code with UI structure. This makes UI maintenance difficult and violates separation of concerns.</p>
<p><strong>Steps:</strong>
1. Create a proper <code>templates</code> directory with static HTML files
2. Move the existing HTML template to a static file
3. Update <code>src/deployment/local.py</code> to use Jinja2 templates properly
4. Separate UI concerns from backend logic
5. Add CSS and JavaScript as separate files in a <code>static</code> directory
6. Implement proper error handling and user feedback
7. Add responsive design elements for better mobile support</p>
<p><strong>Success Criteria:</strong>
- Clean separation of UI and backend code
- Improved maintainability of the UI components
- Proper use of Jinja2 templates
- Responsive design that works on desktop and mobile
- No regression in functionality</p>
<p><strong>Resources:</strong>
- <a href="https://fastapi.tiangolo.com/advanced/templates/">FastAPI Templates Documentation</a>
- <a href="https://jinja.palletsprojects.com/">Jinja2 Documentation</a></p>
<hr />
<h3 id="ai-004-align-testing-framework-with-standards">AI-004: Align Testing Framework with Standards</h3>
<p><strong>Priority:</strong> Low<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 15, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
The project currently uses <code>unittest</code> while our company standards specify Pytest. We need to migrate our tests to align with our standards and improve test coverage.</p>
<p><strong>Steps:</strong>
1. Convert existing test classes from <code>unittest</code> to Pytest style
2. Implement fixtures where appropriate to reduce code duplication
3. Add explicit failure case tests for agent execution
4. Implement parameterized tests for edge cases
5. Add integration tests for the CLI and web interfaces
6. Update CI/CD pipeline to use Pytest
7. Add code coverage reporting</p>
<p><strong>Success Criteria:</strong>
- All tests passing with Pytest
- Improved test coverage (target: &gt;80%)
- Explicit testing of failure cases
- Comprehensive fixtures for common test scenarios
- CI/CD pipeline updated to use Pytest</p>
<p><strong>Resources:</strong>
- <a href="https://docs.pytest.org/">Pytest Documentation</a>
- <a href="https://docs.pytest.org/en/stable/fixture.html">Pytest Fixtures Guide</a>
- <a href="https://docs.pytest.org/en/stable/parametrize.html">Pytest Parameterization</a></p>
<hr />
<h3 id="ai-005-review-pydantic-usage">AI-005: Review Pydantic Usage</h3>
<p><strong>Priority:</strong> Low<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 15, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
There is inconsistent use of Pydantic in agent classes. Some configuration parameters are stored as regular instance attributes rather than Pydantic fields, which works but is slightly unconventional.</p>
<p><strong>Steps:</strong>
1. Review current Pydantic usage across the codebase
2. Decide on a consistent approach (Pydantic fields vs. regular attributes)
3. Update agent classes to follow the chosen approach
4. Add validation for configuration parameters
5. Document the chosen approach for future development
6. Update tests to reflect any changes</p>
<p><strong>Success Criteria:</strong>
- Consistent Pydantic usage across the codebase
- Proper validation of configuration parameters
- Updated documentation reflecting the chosen approach
- All tests passing with the updated implementation</p>
<p><strong>Resources:</strong>
- <a href="https://docs.pydantic.dev/">Pydantic Documentation</a>
- <a href="https://docs.pydantic.dev/latest/usage/best-practices/">Pydantic Best Practices</a></p>
<hr />
<h3 id="ai-006-implement-vertex-ai-agent-engine-deployment">AI-006: Implement Vertex AI Agent Engine Deployment</h3>
<p><strong>Priority:</strong> High<br />
<strong>Owner:</strong> CTO<br />
<strong>Due Date:</strong> May 5, 2025<br />
<strong>Status:</strong> Completed</p>
<p><strong>Description:</strong><br />
Vertex AI Agent Engine is a fully managed service specifically designed for AI agents, offering advantages over traditional Vertex AI endpoints. We need to implement a deployment mechanism for Agent Engine to provide our users with a more robust and scalable deployment option.</p>
<p><strong>Steps:</strong>
1. Create a new deployment script (<code>deploy_agent_engine.py</code>) for Agent Engine deployment
2. Implement environment-specific configuration loading
3. Add support for Google Cloud Storage bucket staging
4. Implement local testing before deployment
5. Add remote testing after deployment
6. Create comprehensive documentation for Agent Engine deployment
7. Update existing documentation to reference the new deployment option</p>
<p><strong>Success Criteria:</strong>
- Successful deployment of our custom agent to Vertex AI Agent Engine
- Verification that the deployed agent functions correctly
- Comprehensive documentation for Agent Engine deployment
- Updated existing documentation to reference the new deployment option
- End-to-end testing with sample queries</p>
<p><strong>Resources:</strong>
- <a href="https://cloud.google.com/vertex-ai/docs/agent-engine/overview">Vertex AI Agent Engine Documentation</a>
- <a href="https://cloud.google.com/vertex-ai/docs/agent-development-kit/agent-engine">Google ADK Agent Engine Integration Guide</a></p>
<h2 id="next-steps">Next Steps</h2>
<ol>
<li><strong>Team Meeting:</strong> Schedule a team meeting by April 23, 2025, to discuss these action items and assign owners.</li>
<li><strong>Sprint Planning:</strong> Incorporate these items into our next sprint planning session (April 25, 2025).</li>
<li><strong>Documentation Update:</strong> Update our technical documentation to reflect the planned changes by April 26, 2025.</li>
<li><strong>Progress Tracking:</strong> Set up weekly check-ins (every Monday) to track progress on these items.</li>
</ol>
<h2 id="approval">Approval</h2>
<ul>
<li>[ ] CTO</li>
<li>[ ] Lead Developer</li>
<li>[ ] Product Manager</li>
</ul>
<h2 id="changelog">Changelog</h2>
<table>
<thead>
<tr>
<th>Date</th>
<th>Author</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Initial creation based on code review report</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Implemented AI-001: Fixed Vertex AI Deployment Mechanism</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Implemented AI-002: Improved CLI Extensibility</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Implemented AI-003: Refactored Local Deployment UI</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Started AI-004: Added tests for registry, local deployment UI, and Vertex AI deployment</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Continued AI-004: Fixed test failures and improved test coverage</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Completed AI-004: Migrated tests from unittest to pytest and added test report</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Started AI-005: Reviewed Pydantic usage and created standardization guidelines</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Completed AI-005: Implemented hybrid approach for Pydantic usage with validation methods</td>
</tr>
<tr>
<td>April 21, 2025</td>
<td>[Your Name], CTO</td>
<td>Implemented AI-006: Added Vertex AI Agent Engine deployment support</td>
</tr>
</tbody>
</table>
        
        <div class="footer">
            <p>Generated on 2025-04-21 09:00:31</p>
            <p><a href="index.html">Back to Documentation Index</a></p>
        </div>
    </body>
    </html>
    